{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "class MarkovChain(object):\n",
    "    def __init__(self, transition_prob):\n",
    "        \"\"\"\n",
    "        Initialize the MarkovChain instance.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_prob: dict\n",
    "            A dict object representing the transition \n",
    "            probabilities in Markov Chain. \n",
    "            Should be of the form: \n",
    "                {'state1': {'state1': 0.1, 'state2': 0.4}, \n",
    "                 'state2': {...}}\n",
    "        \"\"\"\n",
    "        self.transition_prob = transition_prob\n",
    "        self.states = list(transition_prob.keys())\n",
    " \n",
    "    def next_state(self, current_state):\n",
    "        \"\"\"\n",
    "        Returns the state of the random variable at the next time \n",
    "        instance.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: str\n",
    "            The current state of the system.\n",
    "        \"\"\"\n",
    "        return np.random.choice(\n",
    "            self.states, \n",
    "            p=[self.transition_prob[current_state][next_state] \n",
    "               for next_state in self.states]\n",
    "        )\n",
    " \n",
    "    def generate_states(self, current_state, no=10):\n",
    "        \"\"\"\n",
    "        Generates the next states of the system.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: str\n",
    "            The state of the current random variable.\n",
    " \n",
    "        no: int\n",
    "            The number of future states to generate.\n",
    "        \"\"\"\n",
    "        future_states = []\n",
    "        for i in range(no):\n",
    "            next_state = self.next_state(current_state)\n",
    "            future_states.append(next_state)\n",
    "            current_state = next_state\n",
    "        return future_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.19, \n",
    " 'Snowy': 0.01},\n",
    " 'Rainy': {'Sunny': 0.2, 'Rainy': 0.7,\n",
    " 'Snowy': 0.1},\n",
    " 'Snowy': {'Sunny': 0.1, 'Rainy': 0.2,\n",
    " 'Snowy': 0.7}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_chain = MarkovChain(transition_prob=transition_prob)\n",
    "weather_chain.next_state(current_state='Sunny')\n",
    "weather_chain.next_state(current_state='Snowy')\n",
    "weather_chain.generate_states(current_state='Snowy', no=10)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "\n",
    "data = df[['v1', 'v2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Iterate through each message, tokenize and normalize it. Each processed token is then added to the \n",
    "word_dict which is a nested dictionary holding all the tokens that follow the given token along with \n",
    "their count corresponding to this token.\n",
    "\n",
    "E.g.,\n",
    "{\n",
    "    \"token_1\": {\"token_2\": 10, \"token_3\": 5}\n",
    "}\n",
    "\n",
    "This data will be used to calculate the probability of each following token given the primary token.\n",
    "The calculated probability is the transition probability from token_1 to token_2 and token_3.\n",
    "\"\"\"\n",
    "word_dict = {}\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    \"\"\"\n",
    "    Fetch the class and the message into two separate variables.\n",
    "    \"\"\"\n",
    "    tag = row['v1']\n",
    "    message = row['v2']\n",
    "    \n",
    "    \"\"\"\n",
    "    Tokenize the message text and normalize it by removing the punctuations.\n",
    "    \"\"\"\n",
    "    msg_tokens = word_tokenize(message)\n",
    "    last_token = None\n",
    "    \n",
    "    for token in msg_tokens:\n",
    "        normalized_token = token.lower()\n",
    "\n",
    "        if normalized_token in string.punctuation:\n",
    "            continue\n",
    "        \n",
    "        \"\"\"\n",
    "        Lemmatize the word before adding it to the markov chain.\n",
    "        \"\"\"\n",
    "        lemmatized_token = wordnet_lemmatizer.lemmatize(normalized_token)\n",
    "        \n",
    "        if last_token not None:\n",
    "            word_dict[last_token]\n",
    "            \n",
    "    \n",
    "    if index > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
